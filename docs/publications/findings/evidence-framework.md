# Evidence Credibility Framework

**Purpose:** Classify all research claims by evidence strength to maintain credibility in blog posts and publications.

**Last Updated:** 2025-12-31

---

## Evidence Levels

### üü¢ PRIMARY (Highest Credibility)
**Definition:** Peer-reviewed academic papers, government studies with quantified data, empirical research with sample sizes, our own reproducible testing.

**Usage:** Can state as fact with citation.

**Format:** "According to [Author] ([Year]), [claim]"

**Examples:**
- Panko's peer-reviewed spreadsheet error research (multiple studies, published in *Journal of Organizational and End User Computing* 2008)
- Poh & Chen (1998) Singapore buildability study (37 projects, published in *Construction Management and Economics*)
- Kytinou et al. (2021) sensitivity analysis for RC beams (*Applied Sciences*)
- Vabalas et al. (2019) ML small sample limitations (*PLOS One*)

---

### üü° SECONDARY (Moderate Credibility)
**Definition:** Industry reports, government websites, documented case studies, technical articles from reputable sources, research aggregators/consortia.

**Usage:** Can state with qualifier like "industry reports suggest" or "documented case shows" or "research synthesis indicates"

**Format:** "[Organization] reports that [claim]" or "In a documented case, [event]" or "[Consortium] aggregates research showing [claim]"

**Examples:**
- EuSpRIG research synthesis (aggregates 193 peer-reviewed papers, but is itself a secondary source)
- EuSpRIG horror stories database (aggregates publicly reported cases from news/regulators)
- BCA Singapore official guidelines (government source but not empirical study)
- SkyCiv industry blog posts (vendor but cites industry trends)
- Our product review (13 products examined, not exhaustive market scan)

---

### üü† ANECDOTAL (Lower Credibility)
**Definition:** Forum posts, single user experiences, blog comments, vendor marketing without data.

**Usage:** Must explicitly label as anecdotal. Use for illustration, not primary evidence.

**Format:** "One engineer reported on [forum]..." or "Forum discussions suggest..."

**Examples:**
- ETABS API reliability from single ResearchGate post
- "10-20 iterations per beam" (no source - should be removed or marked as assumption)
- Engineer pain points from single Eng-Tips threads

---

### üî¥ UNVERIFIED / OVERCLAIMED (Not Credible)
**Definition:** Claims made without sources, generalizations beyond data, extrapolations not supported.

**Usage:** DO NOT USE or re-scope with caveats.

**Format:** N/A - revise or remove

**Examples:**
- "7-10% cost savings" for BDAS (not found in Poh & Chen 1998 primary source)
- "ML requires thousands of samples" (general but not quantified from sources)
- "100% accuracy" (overclaim - should be "100% match on 3 test vectors")

---

## Corrected Claims ‚Äî High-Priority Fixes

### ‚ùå CLAIM: "7-10% cost and time savings" from Singapore BDAS
**Original Sources:** BCA website, Asian Journal paper
**Investigation:** Poh & Chen (1998) validated labor productivity improvement but did NOT quantify 7-10% savings. The number cannot be verified from primary sources.

**CORRECTED VERSION:**
> "Singapore's Building and Construction Authority promotes buildability scoring through its BDAS framework. Poh & Chen's 1998 empirical study of 37 completed projects validated that higher buildable scores correlate with improved labor productivity."
>
> **Evidence Level:**
> - üü¢ PRIMARY: Poh & Chen productivity correlation (37 projects, peer-reviewed)
> - üü° SECONDARY: BCA framework promotion (government framework, mandate details vary by project type)
>
> **Citation:** Poh, P., & Chen, J. (1998). The Singapore buildable design appraisal system: A preliminary review of the relationship between buildability, site productivity and cost. *Construction Management and Economics*, 16(6), 681-692.
>
> **Language change:** "Mandates" ‚Üí "Promotes" (softened without direct BCA source for specific mandate requirements)

---

### ‚ùå CLAIM: "80-90% of spreadsheets contain errors"
**Original Source:** Maplesoft vendor marketing page
**Investigation:** Found primary academic sources - Panko's research and EuSpRIG synthesis.

**CORRECTED VERSION:**
> "Fifteen years of peer-reviewed research by Raymond Panko found that cell error rates average 1.1% to 5.6% in controlled experiments, meaning large spreadsheets likely contain multiple errors. The most rigorous field audits found errors in at least 86% of spreadsheets audited (Panko 2008). EuSpRIG's research synthesis (aggregating 193 peer-reviewed papers) concludes that >90% of spreadsheets contain errors based on human error research."
>
> **Evidence Level:**
> - üü¢ PRIMARY: Panko (2008) peer-reviewed research - cell error rates, field audit rates
> - üü° SECONDARY: EuSpRIG synthesis (aggregator of 193 peer-reviewed papers, not primary author)
>
> **Citations:**
> - Panko, R. R. (2008). What we know about spreadsheet errors. *Journal of Organizational and End User Computing*, 20(2), 15-30.
> - EuSpRIG (European Spreadsheet Risks Interest Group). Research synthesis. https://eusprig.org/research-info/research-and-best-practice/
>
> **Real-world impacts** (üü° SECONDARY - EuSpRIG aggregates public reports):
> - UK COVID-19: 16,000 cases lost to Excel row limit (2020)
> - Norway sovereign fund: $92M lost to date entry error (2024)
> - Standard Chartered: ¬£46.55M fine for ¬£8B calculation error (2021)
> - **Source:** [EuSpRIG Horror Stories](https://eusprig.org/research-info/horror-stories/) (secondary aggregation of news reports and regulatory filings)
> - **Removed:** Unverified mortality estimate for UK COVID case

---

### ‚ùå CLAIM: "ETABS API fails 8 out of 10 times on startup"
**Original Source:** Single ResearchGate forum post
**Investigation:** One user's experience, not a systematic study.

**CORRECTED VERSION:**
> "Engineers report reliability challenges with ETABS API automation. In forum discussions, users describe intermittent startup failures requiring Task Manager intervention, version compatibility issues between ETABS 18 and 19, and runtime errors when interfacing with Excel VBA. These integration challenges motivate robust post-processing libraries for design calculations after forces are extracted from analysis software."
>
> **Evidence Level:** üü† ANECDOTAL (forum posts, not systematic study)
> **Citation:** ResearchGate discussion thread (2020+), Eng-Tips forum threads.
> **Usage Note:** Illustrate integration pain points, not quantified reliability claim.

---

### ‚ùå CLAIM: "100% accuracy on all test cases"
**Original Context:** Prototype validation with 3-4 golden vectors
**Investigation:** Accurate for sample tested, but "100% accuracy" implies general accuracy.

**CORRECTED VERSION:**
> "Sensitivity analysis, predictive validation, and constructability scoring features achieved 100% match against 3-4 golden vectors from IS 456 worked examples (sample-only validation). All outputs are deterministic (same inputs always produce same outputs) and traceable to code clauses."
>
> **Evidence Level:** üü¢ PRIMARY (our own testing, reproducible)
> **Scope Limitation:** Sample validation, not general accuracy claim. Validated on worked examples, not field data.
> **Usage Note:** Emphasize determinism and traceability, not absolute accuracy.

---

### ‚ùå CLAIM: "ML requires thousands of samples"
**Original Context:** General ML criticism without specific citation
**Investigation:** Found academic papers on sample size requirements.

**CORRECTED VERSION:**
> "Academic research on machine learning with small datasets shows that insufficient sample sizes lead to overfitting and strongly biased performance estimates. A 2019 PLOS One study found that small sample sizes are associated with higher reported classification accuracy (false confidence). For supervised learning, annotated data is expensive to obtain, and methods exist to predict required sample sizes for target performance levels. In contrast, deterministic methods based on physical models (like IS 456 equations) require zero training data and can be validated with small numbers of verified test cases."
>
> **Evidence Level:** üü¢ PRIMARY (peer-reviewed papers)
> **Citations:**
> - Vabalas et al. (2019). Machine learning algorithm validation with a limited sample size. *PLOS One*.
> - Figueroa et al. (2012). Predicting sample size required for classification performance. *BMC Medical Informatics and Decision Making*.
> **Usage Note:** Focus on overfitting risk with small data, not arbitrary "thousands" threshold.

---

### ‚ùå CLAIM: "Engineers iterate 10-20 times per beam" / "Majority of engineers use trial-and-error"
**Original Context:** Assumed typical workflow, no source for specific counts or "majority" quantifier
**Investigation:** Found academic papers describing trial-and-error workflow but not quantifying usage rates or iteration counts.

**CORRECTED VERSION:**
> "Academic literature describes that structural engineers commonly complete designs through trial-and-error workflows, iteratively revising designs until all building codes are satisfied. For optimization studies, structural simulations can take 2-15 minutes per iteration, meaning a full optimization process can take days to converge. Smart features like sensitivity analysis and predictive validation help reduce iteration cycles by identifying critical parameters and flagging potential failures early."
>
> **Evidence Level:** üü° SECONDARY (academic papers describe workflow, don't provide usage statistics)
> **Citation:**
> - Chang, D., et al. (2020). Learning to simulate and design for structural engineering. *ICML Proceedings*.
> - Kaveh, A. (2025). Design optimization in structural engineering: Computational techniques. *American Journal of Mechanical and Materials Engineering*.
>
> **Language changes:**
> - "Majority of engineers" ‚Üí "Engineers commonly" (removed unsupported quantifier)
> - "10-20 iterations" ‚Üí Removed (no source for specific counts)
>
> **Usage Note:** Describe trial-and-error pattern without claiming specific usage rates or iteration counts.

---

### ‚ùå CLAIM: "No product offers [feature X]"
**Original Context:** Competitive analysis of ~13 products
**Investigation:** Limited review, not exhaustive market scan.

**CORRECTED VERSION:**
> "In our review of commercial tools (Tedds, ETABS, Revit, SkyCiv, ENERCALC), Excel add-ins (SMART Engineer, custom spreadsheets), and open-source libraries (PyNite, ConcreteProperties, FoundationDesign), we found no evidence of sensitivity analysis, predictive validation, or constructability scoring features for Excel-native beam design workflows (as of December 2025 review)."
>
> **Evidence Level:** üü° SECONDARY (our own review, limited scope)
> **Scope Limitation:** 13 products reviewed, not exhaustive market analysis.
> **Usage Note:** State what we found in our review, not absolute market claims.

---

## Blog Writing Guidelines

### DO:
‚úÖ Cite primary sources with full references
‚úÖ Use evidence level tags internally (don't show tags in blog, but track for fact-checking)
‚úÖ Qualify claims with scope ("in our review," "studies show," "documented cases include")
‚úÖ Provide real examples (UK COVID, Norway fund, Standard Chartered) for impact
‚úÖ Link to sources in footnotes or inline citations

### DON'T:
‚ùå Use vendor marketing as sole source for statistics
‚ùå Present forum posts as systematic data
‚ùå Extrapolate beyond what sources actually say
‚ùå Make absolute claims ("all," "never," "only") without exhaustive evidence
‚ùå Overclaim validation scope ("100% accurate" ‚Üí "100% match on test sample")

---

## Updated Statistics Table ‚Äî Blog-Ready

| Claim | Evidence Level | Corrected Statement | Citation |
|-------|----------------|---------------------|----------|
| Spreadsheet errors | üü¢ PRIMARY | 86%+ of field-audited spreadsheets contained errors (rigorous audits); cell error rates 1.1-5.6% | Panko (2008), EuSpRIG |
| Real error impact | üü¢ PRIMARY | UK COVID: 16,000 cases lost; Norway: $92M lost; Standard Chartered: ¬£46.55M fine | EuSpRIG horror stories database |
| BDAS productivity | üü¢ PRIMARY | Higher buildable scores correlate with improved labor productivity (37 projects) | Poh & Chen (1998) |
| BDAS cost savings | üî¥ UNVERIFIED | Cannot verify 7-10% claim from primary source | Remove or re-source |
| ETABS API issues | üü† ANECDOTAL | Engineers report intermittent failures, version incompatibilities | Forum discussions (illustrative only) |
| Trial-and-error design | üü° SECONDARY | Majority of engineers use iterative trial-and-error workflows | Academic papers (2020, 2025) |
| ML sample requirements | üü¢ PRIMARY | Small samples lead to overfitting and biased estimates | Vabalas et al. (2019), Figueroa et al. (2012) |
| Our validation | üü¢ PRIMARY | 100% match on 3-4 IS 456 golden vectors (sample-only) | Our testing, reproducible |

---

## Citation Format (APA Style)

### Academic Papers
Panko, R. R. (2008). What we know about spreadsheet errors. *Journal of Organizational and End User Computing*, 20(2), 15-30.

Poh, P., & Chen, J. (1998). The Singapore buildable design appraisal system: A preliminary review of the relationship between buildability, site productivity and cost. *Construction Management and Economics*, 16(6), 681-692.

Vabalas, A., Gowen, E., Poliakoff, E., & Casson, A. J. (2019). Machine learning algorithm validation with a limited sample size. *PLOS One*, 14(11), e0224365.

Figueroa, R. L., Zeng-Treitler, Q., Kandula, S., & Ngo, L. H. (2012). Predicting sample size required for classification performance. *BMC Medical Informatics and Decision Making*, 12, 8.

### Industry Sources
European Spreadsheet Risks Interest Group (EuSpRIG). (2000-present). Research and best practice. Retrieved from https://eusprig.org/research-info/research-and-best-practice/

Building and Construction Authority (BCA), Singapore. (2019). Buildability and constructability framework. Retrieved from https://www1.bca.gov.sg/buildsg/productivity/buildability-buildable-design-and-constructability

### Horror Stories (Documented Cases)
EuSpRIG. (2020). UK COVID-19 contact tracing: Excel error loses 16,000 cases. Horror Stories Database. Retrieved from https://eusprig.org/research-info/horror-stories/

---

## Evidence Audit Checklist

Before publishing any blog post:

- [ ] All statistics cited to primary sources (peer-reviewed papers or government studies)
- [ ] Anecdotal evidence explicitly labeled (e.g., "engineers report," "forum discussions suggest")
- [ ] No absolute claims ("only," "no product") unless exhaustively verified
- [ ] Validation scope clearly stated (e.g., "3 test vectors" not "100% accurate")
- [ ] Real-world examples include specific details (dates, amounts, sources)
- [ ] All sources linked in footnotes or references section
- [ ] Internal evidence tags removed from final blog copy (use for fact-checking only)

---

**Status:** ‚úÖ Framework complete ‚Äî Ready for findings document updates
**Next Step:** Apply evidence tags to all findings documents (01, 02, 03, 00)
