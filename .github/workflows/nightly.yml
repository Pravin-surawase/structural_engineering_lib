name: Nightly QA

on:
  schedule:
    # ~11:30pm India (UTC+5:30). Adjust as needed.
    - cron: "0 18 * * *"
  workflow_dispatch:

# Default to least-privilege for the workflow. Jobs can widen if needed.
permissions:
  contents: write
  issues: write
  pull-requests: write

jobs:
  nightly:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout
        uses: actions/checkout@v6

      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: "3.12"

      - name: Install package (dev + dxf)
        working-directory: Python
        run: |
          python -m pip install --upgrade pip
          python -m pip install -e ".[dev,dxf]"

      - name: Run tests
        working-directory: Python
        run: |
          python -m pytest -q

      # ================================================================
      # TASK-503: Performance Regression Tracking
      # ================================================================
      - name: Run performance benchmarks
        working-directory: Python
        run: |
          python -m pytest tests/performance/test_benchmarks.py \
            --benchmark-only \
            --benchmark-json=../benchmark-results.json \
            -v
        continue-on-error: true

      - name: Store benchmark results
        uses: benchmark-action/github-action-benchmark@v1
        with:
          name: IS 456 Performance Benchmarks
          tool: 'pytest'
          output-file-path: benchmark-results.json
          github-token: ${{ secrets.GITHUB_TOKEN }}
          auto-push: true
          alert-threshold: '150%'
          comment-on-alert: true
          fail-on-alert: false
          alert-comment-cc-users: '@Pravin-surawase'
          benchmark-data-dir-path: 'dev/benchmark-data'
        continue-on-error: true

      - name: Upload benchmark artifacts
        uses: actions/upload-artifact@v6
        with:
          name: benchmark-results
          path: benchmark-results.json
          retention-days: 90
        if: always()

      - name: Check documentation links
        run: |
          python scripts/check_links.py --fail-fast
        continue-on-error: true  # Don't fail entire workflow on broken links

      - name: Smoke test CLI pipeline
        working-directory: Python
        run: |
          mkdir -p ../artifacts
          python -m structural_lib design examples/sample_beam_design.csv -o ../artifacts/results.json
          python -m structural_lib bbs ../artifacts/results.json -o ../artifacts/schedule.csv
          python -m structural_lib dxf ../artifacts/results.json -o ../artifacts/drawings.dxf
          python -m structural_lib job examples/sample_job_is456.json -o ../artifacts/job_out
          python -m structural_lib critical ../artifacts/job_out --top 5 --format csv -o ../artifacts/critical.csv
          python -m structural_lib report ../artifacts/job_out --format html -o ../artifacts/report.html
          python -m structural_lib report ../artifacts/results.json --format html -o ../artifacts/report_design --batch-threshold 1

      - name: Build wheel for release verification
        working-directory: Python
        run: |
          python -m pip install --upgrade build
          python -m build --wheel --outdir dist

      - name: Verify wheel install in clean venv
        run: |
          python scripts/verify_release.py --source wheel --wheel-dir Python/dist

      - name: Summarize results
        run: |
          python - <<'PY'
          import json
          from pathlib import Path

          results_path = Path("artifacts/results.json")
          if not results_path.exists():
              raise SystemExit("Missing artifacts/results.json")

          data = json.loads(results_path.read_text(encoding="utf-8"))
          summary = data.get("summary", {})
          beams = data.get("beams", [])
          max_util = max((b.get("governing_utilization", 0.0) for b in beams), default=0.0)

          print("Nightly summary")
          print(f"- beams: {summary.get('total_beams')}")
          print(f"- passed: {summary.get('passed')}")
          print(f"- failed: {summary.get('failed')}")
          print(f"- max governing utilization: {max_util:.3f}")
          PY

      - name: Upload artifacts
        if: always()
        uses: actions/upload-artifact@v6
        with:
          name: nightly-artifacts
          path: |
            artifacts/results.json
            artifacts/schedule.csv
            artifacts/drawings.dxf
            artifacts/critical.csv
            artifacts/report.html
            artifacts/report_design
            artifacts/job_out
          if-no-files-found: warn

      - name: Create issue on failure
        if: failure()
        uses: actions/github-script@v8
        with:
          script: |
            const title = `Nightly QA failed (${new Date().toISOString().slice(0, 10)})`;
            const body = [
              "Nightly QA failed.",
              "",
              `Run: ${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}`,
            ].join("\n");

            const { data: issues } = await github.rest.issues.listForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
              state: "open",
            });

            if (issues.some((issue) => issue.title === title)) {
              return;
            }

            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title,
              body,
            });
